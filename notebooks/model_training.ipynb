{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f10b8ab",
   "metadata": {},
   "source": [
    "# LSTM Baseline Model Training - Day 2\n",
    "\n",
    "**Objective**: Train a simple LSTM model to predict container CPU usage 15 minutes ahead\n",
    "\n",
    "## Approach:\n",
    "1. Load and prepare data with sliding windows\n",
    "2. Train LSTM baseline model\n",
    "3. Evaluate predictions\n",
    "4. Save model for future use\n",
    "\n",
    "This serves as proof of concept before building more complex models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4408ad5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msliding_windows\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_features_and_windows\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmodels\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlstm_baseline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     13\u001b[39m     LSTMPredictor,\n\u001b[32m     14\u001b[39m     ModelTrainer,\n\u001b[32m     15\u001b[39m     prepare_data_for_training,\n\u001b[32m     16\u001b[39m     evaluate_predictions\n\u001b[32m     17\u001b[39m )\n\u001b[32m     19\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Libraries imported\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mnt/f/DPN/AWS/MLOPs/predictive-autoscaling/notebooks/../src/models/lstm_baseline.py:8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[33;03mLSTM Baseline Model for Container CPU Prediction\u001b[39;00m\n\u001b[32m      3\u001b[39m \n\u001b[32m      4\u001b[39m \u001b[33;03mA simple LSTM model to predict future CPU usage based on historical patterns.\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03mThis serves as a baseline for more complex models.\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnn\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moptim\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from preprocessing.sliding_windows import create_features_and_windows\n",
    "from models.lstm_baseline import (\n",
    "    LSTMPredictor,\n",
    "    ModelTrainer,\n",
    "    prepare_data_for_training,\n",
    "    evaluate_predictions\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de0e6571",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Load the most recent metrics export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd70990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find and load latest metrics file\n",
    "data_dir = '../data/raw'\n",
    "metrics_files = glob.glob(os.path.join(data_dir, 'metrics_*.csv'))\n",
    "\n",
    "if not metrics_files:\n",
    "    print(\"‚ùå No metrics files found! Run export script first.\")\n",
    "else:\n",
    "    latest_file = max(metrics_files, key=os.path.getctime)\n",
    "    print(f\"üìÅ Loading: {os.path.basename(latest_file)}\")\n",
    "    \n",
    "    df = pd.read_csv(latest_file)\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(df):,} records\")\n",
    "    print(f\"   Time range: {pd.to_datetime(df['timestamp']).min()} to {pd.to_datetime(df['timestamp']).max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dee3e92",
   "metadata": {},
   "source": [
    "## 2. Create Sliding Windows\n",
    "\n",
    "Create 60-minute input windows to predict 15 minutes ahead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14042cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features and windows\n",
    "print(\"üîÑ Creating sliding windows...\")\n",
    "print(\"   Input: 60 minutes of history\")\n",
    "print(\"   Output: Predict next 15 minutes\")\n",
    "\n",
    "try:\n",
    "    X, y, feature_names, metadata = create_features_and_windows(\n",
    "        df=df,\n",
    "        container_name='metrics-webapp',\n",
    "        metric_name='container_cpu',\n",
    "        window_size_minutes=60,\n",
    "        prediction_horizon_minutes=15,\n",
    "        include_temporal=True,\n",
    "        include_lags=True,\n",
    "        include_rolling=True\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n‚úÖ Created {len(X)} training samples\")\n",
    "    print(f\"   X shape: {X.shape}\")\n",
    "    print(f\"   y shape: {y.shape}\")\n",
    "    print(f\"   Features: {len(feature_names)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating windows: {e}\")\n",
    "    print(\"   This might happen if there's not enough data yet.\")\n",
    "    print(\"   Try running more load patterns and collecting more data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe17e28",
   "metadata": {},
   "source": [
    "## 3. Prepare Data for Training\n",
    "\n",
    "Split into train/validation sets and normalize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42ebf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "train_loader, val_loader, scalers = prepare_data_for_training(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    train_split=0.8,\n",
    "    batch_size=32,\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "X_scaler, y_scaler = scalers\n",
    "\n",
    "print(\"\\n‚úÖ Data preparation complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06478a17",
   "metadata": {},
   "source": [
    "## 4. Build LSTM Model\n",
    "\n",
    "Create a 2-layer LSTM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c242cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model hyperparameters\n",
    "input_size = X.shape[2]  # Number of features\n",
    "hidden_size = 64\n",
    "num_layers = 2\n",
    "prediction_horizon = y.shape[1]  # Number of timesteps to predict\n",
    "dropout = 0.2\n",
    "\n",
    "# Create model\n",
    "model = LSTMPredictor(\n",
    "    input_size=input_size,\n",
    "    hidden_size=hidden_size,\n",
    "    num_layers=num_layers,\n",
    "    prediction_horizon=prediction_horizon,\n",
    "    dropout=dropout\n",
    ")\n",
    "\n",
    "# Count parameters\n",
    "n_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(\"üß† LSTM Model Architecture:\")\n",
    "print(\"=\" * 60)\n",
    "print(model)\n",
    "print(\"=\" * 60)\n",
    "print(f\"Total trainable parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6707329b",
   "metadata": {},
   "source": [
    "## 5. Train Model\n",
    "\n",
    "Train with early stopping to prevent overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526ae42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create trainer\n",
    "trainer = ModelTrainer(\n",
    "    model=model,\n",
    "    device='cpu',  # Change to 'cuda' if GPU available\n",
    "    learning_rate=0.001\n",
    ")\n",
    "\n",
    "print(\"üöÄ Starting training...\")\n",
    "print(\"   This may take a few minutes...\\n\")\n",
    "\n",
    "# Train model\n",
    "history = trainer.train(\n",
    "    train_loader=train_loader,\n",
    "    val_loader=val_loader,\n",
    "    epochs=100,\n",
    "    patience=15,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beb2d845",
   "metadata": {},
   "source": [
    "## 6. Visualize Training\n",
    "\n",
    "Plot training and validation loss curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e5fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "trainer.plot_training_history()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014dfe75",
   "metadata": {},
   "source": [
    "## 7. Evaluate Model\n",
    "\n",
    "Make predictions on validation set and evaluate performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b8db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get validation data\n",
    "split_idx = int(len(X) * 0.8)\n",
    "X_val = X[split_idx:]\n",
    "y_val = y[split_idx:]\n",
    "\n",
    "# Normalize validation data\n",
    "n_val, window_size, n_features = X_val.shape\n",
    "X_val_reshaped = X_val.reshape(-1, n_features)\n",
    "X_val_scaled = X_scaler.transform(X_val_reshaped)\n",
    "X_val_normalized = X_val_scaled.reshape(n_val, window_size, n_features)\n",
    "\n",
    "# Make predictions\n",
    "print(\"üîÆ Making predictions on validation set...\")\n",
    "y_pred_normalized = trainer.predict(X_val_normalized)\n",
    "\n",
    "# Denormalize predictions\n",
    "y_pred = y_scaler.inverse_transform(y_pred_normalized)\n",
    "\n",
    "print(f\"‚úÖ Generated {len(y_pred)} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd8c2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictions\n",
    "evaluate_predictions(\n",
    "    y_true=y_val,\n",
    "    y_pred=y_pred,\n",
    "    n_examples=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed02f18c",
   "metadata": {},
   "source": [
    "## 8. Analyze Prediction Horizon\n",
    "\n",
    "How does accuracy degrade as we predict further into the future?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fbedd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error at each timestep in prediction horizon\n",
    "timestep_errors = []\n",
    "\n",
    "for t in range(y_val.shape[1]):\n",
    "    mse_t = np.mean((y_val[:, t] - y_pred[:, t]) ** 2)\n",
    "    timestep_errors.append(np.sqrt(mse_t))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(timestep_errors, linewidth=2, marker='o')\n",
    "plt.xlabel('Timestep (15-second intervals)', fontsize=12)\n",
    "plt.ylabel('RMSE', fontsize=12)\n",
    "plt.title('Prediction Error vs Time Horizon', fontsize=14, fontweight='bold')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add time labels\n",
    "timesteps_in_minutes = np.arange(0, len(timestep_errors) * 0.25, 3)\n",
    "minute_ticks = (timesteps_in_minutes / 0.25).astype(int)\n",
    "plt.xticks(minute_ticks, [f'{int(m)} min' for m in timesteps_in_minutes])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüìä Error Analysis:\")\n",
    "print(f\"   RMSE at 1 minute:  {timestep_errors[4]:.6f}\")  # 4 timesteps = 1 min\n",
    "print(f\"   RMSE at 5 minutes: {timestep_errors[20]:.6f}\")  # 20 timesteps = 5 min\n",
    "print(f\"   RMSE at 10 minutes: {timestep_errors[40]:.6f}\")  # 40 timesteps = 10 min\n",
    "print(f\"   RMSE at 15 minutes: {timestep_errors[-1]:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beca172",
   "metadata": {},
   "source": [
    "## 9. Save Model\n",
    "\n",
    "Save the trained model and scalers for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef93feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "# Create models directory\n",
    "model_dir = '../src/models/saved'\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "\n",
    "# Save model\n",
    "model_path = os.path.join(model_dir, f'lstm_baseline_{timestamp}.pth')\n",
    "torch.save(model.state_dict(), model_path)\n",
    "\n",
    "# Save scalers\n",
    "scaler_path = os.path.join(model_dir, f'scalers_{timestamp}.pkl')\n",
    "with open(scaler_path, 'wb') as f:\n",
    "    pickle.dump({'X_scaler': X_scaler, 'y_scaler': y_scaler}, f)\n",
    "\n",
    "# Save model config\n",
    "config = {\n",
    "    'input_size': input_size,\n",
    "    'hidden_size': hidden_size,\n",
    "    'num_layers': num_layers,\n",
    "    'prediction_horizon': prediction_horizon,\n",
    "    'dropout': dropout,\n",
    "    'feature_names': feature_names,\n",
    "    'window_size_minutes': 60,\n",
    "    'prediction_horizon_minutes': 15\n",
    "}\n",
    "\n",
    "config_path = os.path.join(model_dir, f'model_config_{timestamp}.pkl')\n",
    "with open(config_path, 'wb') as f:\n",
    "    pickle.dump(config, f)\n",
    "\n",
    "print(\"üíæ Model saved:\")\n",
    "print(f\"   Model weights: {model_path}\")\n",
    "print(f\"   Scalers: {scaler_path}\")\n",
    "print(f\"   Config: {config_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37f0b6c",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "### Model Performance:\n",
    "- **Architecture**: 2-layer LSTM with 64 hidden units\n",
    "- **Input**: 60 minutes of historical data\n",
    "- **Output**: 15-minute CPU usage prediction\n",
    "- **Training**: Early stopping with validation\n",
    "\n",
    "### Next Steps:\n",
    "1. ‚úÖ Baseline LSTM model trained\n",
    "2. Collect more diverse data (spikes, gradual changes, chaos)\n",
    "3. Try more complex models (attention mechanisms, transformers)\n",
    "4. Move to SageMaker for distributed training\n",
    "5. Integrate with Kubernetes HPA\n",
    "\n",
    "### Key Insights:\n",
    "- Document what patterns the model captures well/poorly\n",
    "- Note prediction accuracy at different time horizons\n",
    "- Identify areas for improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac821f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(\"=\" * 60)\n",
    "print(\"DAY 2 MODEL TRAINING - COMPLETE ‚úÖ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nüìä Training Statistics:\")\n",
    "print(f\"   Training samples: {split_idx:,}\")\n",
    "print(f\"   Validation samples: {len(X_val):,}\")\n",
    "print(f\"   Model parameters: {n_params:,}\")\n",
    "print(f\"   Best validation loss: {min(history['val_loss']):.6f}\")\n",
    "\n",
    "print(f\"\\nüéØ Model Performance:\")\n",
    "val_mse = np.mean((y_val - y_pred) ** 2)\n",
    "val_rmse = np.sqrt(val_mse)\n",
    "val_mae = np.mean(np.abs(y_val - y_pred))\n",
    "print(f\"   RMSE: {val_rmse:.6f}\")\n",
    "print(f\"   MAE:  {val_mae:.6f}\")\n",
    "\n",
    "print(f\"\\nüí° Next Actions:\")\n",
    "print(\"   1. Continue collecting data with varied load patterns\")\n",
    "print(\"   2. Experiment with different model architectures\")\n",
    "print(\"   3. Fine-tune hyperparameters\")\n",
    "print(\"   4. Prepare for SageMaker migration\")\n",
    "\n",
    "print(f\"\\nüéâ Day 2 objectives complete!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Predictive Autoscaling",
   "language": "python",
   "name": "predictive-autoscaling"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
